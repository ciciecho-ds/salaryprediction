{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Prediction Project: What leads to a higher salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personal info\n",
    "__author__ = \"Cici Du\"\n",
    "__email__ = \"cicidhz@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from zipfile import ZipFile, Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"../data/data.zip\") as zip:\n",
    "    train_salary = zip.open('data/train_salaries.csv')\n",
    "    train_features = zip.open('data/train_features.csv')\n",
    "    test_features = zip.open('data/test_features.csv')\n",
    "train_salary = pd.read_csv(train_salary)\n",
    "train_features = pd.read_csv(train_features)\n",
    "test_features = pd.read_csv(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets\n",
    "train_df = pd.merge(train_salary, train_features, how='inner', on='jobId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean_data(df):\n",
    "    '''remove jobId and companyId columns, remove records with salary <= 0'''\n",
    "    if 'jobId' in df.columns:\n",
    "        df.drop(['jobId'], axis = 1, inplace = True)\n",
    "    else:\n",
    "        pass\n",
    "    df.drop(['companyId'], axis = 1, inplace = True)\n",
    "    new_df = df.loc[train_df['salary'] > 0]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign categorical and numeric features\n",
    "cat_var = ['jobType','degree','major','industry']\n",
    "num_var = ['yearsExperience','milesFromMetropolis']\n",
    "tar_var = 'salary'\n",
    "\n",
    "def dummy_encode(df,cat_var,num_var):\n",
    "    cat_df = pd.get_dummies(df[cat_var], drop_first=True)\n",
    "    num_df = df[num_var]\n",
    "    return pd.concat([num_df,cat_df,], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_data(train_df)\n",
    "encoded_df = dummy_encode(clean_df,cat_var, num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoded_df\n",
    "y_train = clean_df[tar_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use MSE as evaluation metric\n",
    "def model_average_mse(model):\n",
    "    nmse = cross_val_score(model, x_train,y_train, scoring = 'neg_mean_squared_error')\n",
    "    mean_mse = -1*np.mean(nmse)\n",
    "    print(model)\n",
    "    print('Average MSE is ' + str(mean_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "Average MSE is 384.4143373223809\n"
     ]
    }
   ],
   "source": [
    "#create and train a linear regression model\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(x_train,y_train)\n",
    "model_average_mse(lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train a random forest regressor model\n",
    "#to avoid memory issues during tuning, set the n_estimators as 50\n",
    "rfg_tune = RandomForestRegressor(n_estimators = 50, oob_score = True)\n",
    "#further split the train dataset to tune the random forest regressor\n",
    "x_model_train, x_model_test, y_model_train, y_model_test = train_test_split(x_train,y_train, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936717321642283"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = rfg_tune.fit(x_model_train, y_model_train)\n",
    "rf_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth is 10 OOB Score is 0.6827495167169831\n",
      "depth is 15 OOB Score is 0.7392001518853081\n",
      "depth is 20 OOB Score is 0.7353253480428954\n",
      "depth is 25 OOB Score is 0.7075496861995503\n",
      "depth is 30 OOB Score is 0.6946296693137604\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [10,15,20,25,30]\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    rfg_tune = RandomForestRegressor(n_estimators=50, oob_score=True, random_state=1, n_jobs=2, max_depth=depth)\n",
    "    rf_model = rfg_tune.fit(x_model_train, y_model_train)\n",
    "    print('depth is '+str(depth)+' OOB Score is '+str(rf_model.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features is auto OOB Score is 0.7392001518853081\n",
      "max_features is sqrt OOB Score is 0.7284357345238022\n",
      "max_features is log2 OOB Score is 0.7190039230327228\n",
      "max_features is 0.7 OOB Score is 0.742479279118901\n",
      "max_features is 0.8 OOB Score is 0.7418998215358138\n",
      "max_features is 0.9 OOB Score is 0.7403555732798361\n"
     ]
    }
   ],
   "source": [
    "#Tune max features\n",
    "max_features_list = ['auto','sqrt','log2', 0.7, 0.8, 0.9]\n",
    "\n",
    "for max_features in max_features_list:\n",
    "    rfg_tune = RandomForestRegressor(n_estimators=50, oob_score=True, random_state=1, n_jobs=2, max_depth=15, max_features = max_features)\n",
    "    rf_model = rfg_tune.fit(x_model_train, y_model_train)\n",
    "    print('max_features is '+str(max_features)+' OOB Score is '+str(rf_model.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf is 1 OOB Score is 0.742479279118901\n",
      "min_samples_leaf is 5 OOB Score is 0.743432220042391\n",
      "min_samples_leaf is 10 OOB Score is 0.7437120224839666\n",
      "min_samples_leaf is 20 OOB Score is 0.7435153501623668\n",
      "min_samples_leaf is 30 OOB Score is 0.7432229874978737\n",
      "min_samples_leaf is 50 OOB Score is 0.7418509787997235\n"
     ]
    }
   ],
   "source": [
    "#Tune min_samples_leaf\n",
    "min_samples_leaf_list = [1, 5, 10, 20, 30, 50]\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_list:\n",
    "    rfg_tune = RandomForestRegressor(n_estimators=50, oob_score=True, random_state=1, n_jobs=2, max_depth=15, max_features = 0.7, min_samples_leaf = min_samples_leaf)\n",
    "    rf_model = rfg_tune.fit(x_model_train, y_model_train)\n",
    "    print('min_samples_leaf is '+str(min_samples_leaf)+' OOB Score is '+str(rf_model.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalize the random forest regressor model\n",
    "#increase the number of trees for the final model\n",
    "rfg = RandomForestRegressor(n_estimators=150, oob_score=True, random_state=1, n_jobs=2, max_depth=15, max_features = 0.7, min_samples_leaf = 10)\n",
    "rf_model = rfg.fit(x_train,y_train)\n",
    "model_average_mse(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize feature importances\n",
    "feature_importances = pd.Series(rf_model.feature_importances_, index = x_train.columns)\n",
    "feature_importances.sort_values(inplace = True)\n",
    "feature_importances.plot(kind = 'barh', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_feature_importances(model, features, sum_cols):\n",
    "  feature_dict = dict(zip(features, model.feature_importances_))\n",
    "\n",
    "  for col in sum_cols:\n",
    "    sum_val = sum(x for i, x in feature_dict.items() if col in i)\n",
    "    remove = [i for i in feature_dict.keys() if col in i]\n",
    "    for i in remove:\n",
    "      feature_dict.pop(i)\n",
    "    feature_dict[col] = sum_val \n",
    "  results = pd.Series(feature_dict, index = feature_dict.keys())\n",
    "  results.sort_values(inplace = True)\n",
    "  print(results)\n",
    "  results.plot(kind = 'barh')\n",
    "    \n",
    "combine_feature_importances(rf_model, x_train.columns, cat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions using the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = clean_data(test_features)\n",
    "predict_df = dummy_encode(predict_df, cat_var,num_var)\n",
    "\n",
    "predictions = rf_model.predict(predict_df)\n",
    "\n",
    "def save_model_predictions(model,predictions):\n",
    "    with open('model_predictions.txt', 'w') as file:\n",
    "        file.write(str(model))\n",
    "    np.savetxt('..results/predictions.csv', predictions, delimiter = ',')\n",
    "    \n",
    "save_model_predictions(rf_model, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
